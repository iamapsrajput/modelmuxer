# LiteLLM Proxy Configuration
# Replace REPLACE_WITH_YOUR_XXX_KEY with your actual API keys

model_list:
  # OpenAI Models
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: REPLACE_WITH_YOUR_OPENAI_KEY
      
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: REPLACE_WITH_YOUR_OPENAI_KEY
      
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: REPLACE_WITH_YOUR_OPENAI_KEY

  # Google/Gemini Models
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: REPLACE_WITH_YOUR_GOOGLE_KEY
      
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: REPLACE_WITH_YOUR_GOOGLE_KEY

  # Anthropic Models
  - model_name: claude-3-5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: REPLACE_WITH_YOUR_ANTHROPIC_KEY
      
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: REPLACE_WITH_YOUR_ANTHROPIC_KEY

  # Mistral Models
  - model_name: mistral-small
    litellm_params:
      model: mistral/mistral-small-latest
      api_key: REPLACE_WITH_YOUR_MISTRAL_KEY
      
  - model_name: mistral-large
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: REPLACE_WITH_YOUR_MISTRAL_KEY

# General settings
general_settings:
  # Enable cost tracking
  max_budget: 100.0  # Maximum monthly budget in USD
  budget_duration: 30d
  
  # Fallback settings
  fallbacks:
    - ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"]
    - ["claude-3-5-sonnet", "claude-3-haiku"]
    - ["gemini-1.5-pro", "gemini-1.5-flash"]
  
  # Rate limiting
  rpm: 1000  # requests per minute
  tpm: 100000  # tokens per minute
  
  # Logging
  set_verbose: true
  
  # Cost tracking
  track_cost_per_tenant: true

# Router settings for intelligent model selection
router_settings:
  routing_strategy: "simple-shuffle"  # ModelMuxer will handle advanced routing
  model_group_alias:
    "gpt-4": ["gpt-4o", "gpt-4o-mini"]
    "claude": ["claude-3-5-sonnet", "claude-3-haiku"]
    "gemini": ["gemini-1.5-pro", "gemini-1.5-flash"]
    "mistral": ["mistral-large", "mistral-small"]

# Environment-specific settings
environment_variables:
  LITELLM_LOG: INFO
  LITELLM_REQUEST_TIMEOUT: 600
