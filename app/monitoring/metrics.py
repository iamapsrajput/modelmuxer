# ModelMuxer (c) 2025 Ajay Rajput
# Licensed under Business Source License 1.1 â€“ see LICENSE for details.
"""
Prometheus metrics collection for ModelMuxer.

This module provides comprehensive metrics collection for monitoring
system performance, usage patterns, and health indicators.
"""

import time
from collections import defaultdict
# Type-safe Prometheus imports with proper protocols
from typing import Any, Protocol

import structlog


class CounterProtocol(Protocol):
    def inc(self, amount: float = 1.0) -> None: ...
    def labels(self, **labelkwargs: Any) -> "CounterProtocol": ...


class GaugeProtocol(Protocol):
    def set(self, value: float) -> None: ...
    def labels(self, **labelkwargs: Any) -> "GaugeProtocol": ...


class HistogramProtocol(Protocol):
    def observe(self, amount: float) -> None: ...
    def labels(self, **labelkwargs: Any) -> "HistogramProtocol": ...


class InfoProtocol(Protocol):
    def info(self, val: dict[str, str]) -> None: ...


class RegistryProtocol(Protocol):
    pass


# Try to import Prometheus client
try:
    from prometheus_client import CollectorRegistry as _CollectorRegistry
    from prometheus_client import Counter as _PrometheusCounter
    from prometheus_client import Gauge as _Gauge
    from prometheus_client import Histogram as _Histogram
    from prometheus_client import Info as _Info

    PROMETHEUS_AVAILABLE = True

    # Create factory functions that return the actual Prometheus objects
    def create_counter(
        name: str, documentation: str, labelnames: list[str], registry: Any
    ) -> CounterProtocol:
        """Create a Prometheus counter metric."""
        return _PrometheusCounter(name, documentation, labelnames, registry=registry)

    def create_gauge(
        name: str, documentation: str, labelnames: list[str] | None = None, registry: Any = None
    ) -> GaugeProtocol:
        """Create a Prometheus gauge metric."""
        if labelnames is None:
            return _Gauge(name, documentation, registry=registry)
        return _Gauge(name, documentation, labelnames, registry=registry)

    def create_histogram(
        name: str, documentation: str, labelnames: list[str], buckets: list[float], registry: Any
    ) -> HistogramProtocol:
        """Create a Prometheus histogram metric."""
        return _Histogram(name, documentation, labelnames, buckets=buckets, registry=registry)

    def create_info(name: str, documentation: str, registry: Any) -> InfoProtocol:
        """Create a Prometheus info metric."""
        return _Info(name, documentation, registry=registry)

    def create_registry() -> Any:
        """Create a Prometheus metrics registry."""
        return _CollectorRegistry()

except ImportError:
    PROMETHEUS_AVAILABLE = False

    # Create dummy implementations that match the protocols
    class DummyCounter:
        """Dummy counter implementation when Prometheus is not available."""

        def inc(self, amount: float = 1.0) -> None:
            """Increment counter (no-op)."""
            pass

        def labels(self, **labelkwargs: Any) -> "DummyCounter":
            """Return self for label chaining (no-op)."""
            return self

    class DummyGauge:
        """Dummy gauge implementation when Prometheus is not available."""

        def set(self, value: float) -> None:
            """Set gauge value (no-op)."""
            pass

        def labels(self, **labelkwargs: Any) -> "DummyGauge":
            """Return self for label chaining (no-op)."""
            return self

    class DummyHistogram:
        """Dummy histogram implementation when Prometheus is not available."""

        def observe(self, amount: float) -> None:
            """Observe value in histogram (no-op)."""
            pass

        def labels(self, **labelkwargs: Any) -> "DummyHistogram":
            """Return self for label chaining (no-op)."""
            return self

    class DummyInfo:
        """Dummy info metric implementation when Prometheus is not available."""

        def info(self, val: dict[str, str]) -> None:
            """Set info values (no-op)."""
            pass

    class DummyRegistry:
        """Dummy registry implementation when Prometheus is not available."""

        pass

    def create_counter(
        name: str, documentation: str, labelnames: list[str], registry: Any
    ) -> CounterProtocol:
        """Create a dummy counter when Prometheus is not available."""
        return DummyCounter()

    def create_gauge(
        name: str, documentation: str, labelnames: list[str] | None = None, registry: Any = None
    ) -> GaugeProtocol:
        """Create a dummy gauge when Prometheus is not available."""
        return DummyGauge()

    def create_histogram(
        name: str, documentation: str, labelnames: list[str], buckets: list[float], registry: Any
    ) -> HistogramProtocol:
        """Create a dummy histogram when Prometheus is not available."""
        return DummyHistogram()

    def create_info(name: str, documentation: str, registry: Any) -> InfoProtocol:
        """Create a dummy info metric when Prometheus is not available."""
        return DummyInfo()

    def create_registry() -> Any:
        """Create a dummy registry when Prometheus is not available."""
        return DummyRegistry()


logger = structlog.get_logger(__name__)


class MetricsCollector:
    """
    Comprehensive metrics collector for ModelMuxer.

    Collects and exposes metrics for Prometheus monitoring including
    request metrics, provider performance, routing decisions, and system health.
    """

    def __init__(self, registry: Any = None):
        self.registry = registry or create_registry()

        if not PROMETHEUS_AVAILABLE:
            logger.warning(
                "prometheus_not_available",
                message="Metrics collection disabled - prometheus-client not installed",
            )

        # Initialize metrics using factory functions for type safety

        # Request metrics
        self.request_total = create_counter(
            "modelmuxer_requests_total",
            "Total number of requests",
            ["method", "endpoint", "status_code", "user_id"],
            registry=self.registry,
        )

        self.request_duration = create_histogram(
            "modelmuxer_request_duration_seconds",
            "Request duration in seconds",
            ["method", "endpoint"],
            buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0],
            registry=self.registry,
        )

        # Provider metrics
        self.provider_requests = create_counter(
            "modelmuxer_provider_requests_total",
            "Total requests per provider",
            ["provider", "model", "status"],
            registry=self.registry,
        )

        self.provider_duration = create_histogram(
            "modelmuxer_provider_duration_seconds",
            "Provider response duration",
            ["provider", "model"],
            buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0],
            registry=self.registry,
        )

        self.provider_tokens = create_counter(
            "modelmuxer_provider_tokens_total",
            "Total tokens processed by provider",
            ["provider", "model", "type"],  # token type: input/output
            registry=self.registry,
        )

        self.provider_cost = create_counter(
            "modelmuxer_provider_cost_total",
            "Total cost by provider",
            ["provider", "model"],
            registry=self.registry,
        )

        # Routing metrics
        self.routing_decisions = create_counter(
            "modelmuxer_routing_decisions_total",
            "Routing decisions by strategy",
            ["strategy", "selected_provider", "selected_model"],
            registry=self.registry,
        )

        self.routing_confidence = create_histogram(
            "modelmuxer_routing_confidence",
            "Routing decision confidence scores",
            ["strategy"],
            buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            registry=self.registry,
        )

        # Classification metrics
        self.classification_results = create_counter(
            "modelmuxer_classification_total",
            "Classification results by category",
            ["category", "method"],
            registry=self.registry,
        )

        self.classification_confidence = create_histogram(
            "modelmuxer_classification_confidence",
            "Classification confidence scores",
            ["category"],
            buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            registry=self.registry,
        )

        # Rate limiting metrics
        self.rate_limit_hits = create_counter(
            "modelmuxer_rate_limit_hits_total",
            "Rate limit violations",
            ["user_id", "limit_type"],
            registry=self.registry,
        )

        # Cache metrics
        self.cache_operations = create_counter(
            "modelmuxer_cache_operations_total",
            "Cache operations",
            ["operation", "result"],  # operation: get/set/delete, result: hit/miss/success/error
            registry=self.registry,
        )

        # System metrics
        self.active_connections = create_gauge(
            "modelmuxer_active_connections", "Number of active connections", registry=self.registry
        )

        self.memory_usage = create_gauge(
            "modelmuxer_memory_usage_bytes",
            "Memory usage in bytes",
            labelnames=["type"],  # memory type: rss/vms/shared
            registry=self.registry,
        )

        # Error metrics
        self.errors_total = create_counter(
            "modelmuxer_errors_total",
            "Total errors by type",
            ["error_type", "endpoint", "provider"],
            registry=self.registry,
        )

        # Health metrics
        self.provider_health = create_gauge(
            "modelmuxer_provider_health",
            "Provider health status (1=healthy, 0=unhealthy)",
            labelnames=["provider"],
            registry=self.registry,
        )

        # System info
        self.system_info = create_info(
            "modelmuxer_system_info", "System information", registry=self.registry
        )

        # Enhanced Production Metrics (Part 3)
        # =====================================

        # Cascade routing metrics
        self.cascade_steps_total = create_histogram(
            "modelmuxer_cascade_steps_total",
            "Number of cascade steps per request",
            ["cascade_type", "final_provider"],
            buckets=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
            registry=self.registry,
        )

        self.cost_per_request = create_histogram(
            "modelmuxer_cost_per_request",
            "Cost per request in USD",
            ["provider", "model", "routing_strategy"],
            buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0],
            registry=self.registry,
        )

        self.quality_score_distribution = create_histogram(
            "modelmuxer_quality_score_distribution",
            "Distribution of response quality scores",
            ["provider", "model"],
            buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            registry=self.registry,
        )

        self.confidence_score_distribution = create_histogram(
            "modelmuxer_confidence_score_distribution",
            "Distribution of confidence scores",
            ["provider", "model"],
            buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            registry=self.registry,
        )

        # Budget and cost tracking
        self.budget_utilization_ratio = create_gauge(
            "modelmuxer_budget_utilization_ratio",
            "Budget utilization percentage",
            labelnames=["user_id", "budget_type", "provider"],
            registry=self.registry,
        )

        self.active_users = create_gauge(
            "modelmuxer_active_users",
            "Number of active users in last 24h",
            registry=self.registry,
        )

        # Cache performance
        self.cache_hit_ratio = create_gauge(
            "modelmuxer_cache_hit_ratio",
            "Cache hit percentage",
            labelnames=["cache_type"],
            registry=self.registry,
        )

        # Multi-tenancy metrics
        self.organization_requests = create_counter(
            "modelmuxer_organization_requests_total",
            "Total requests per organization",
            ["org_id", "plan_type"],
            registry=self.registry,
        )

        self.organization_cost = create_counter(
            "modelmuxer_organization_cost_total",
            "Total cost per organization",
            ["org_id", "plan_type"],
            registry=self.registry,
        )

        # Security metrics
        self.auth_attempts = create_counter(
            "modelmuxer_auth_attempts_total",
            "Authentication attempts",
            ["method", "result", "user_type"],
            registry=self.registry,
        )

        self.pii_detections = create_counter(
            "modelmuxer_pii_detections_total",
            "PII detection events",
            ["pii_type", "action_taken"],
            registry=self.registry,
        )

        # Internal tracking
        self.start_time = time.time()
        self.request_counts: defaultdict[str, int] = defaultdict(int)
        self.error_counts: defaultdict[str, int] = defaultdict(int)
        self.active_users_set: set[tuple[str, float]] = set()
        self.last_active_users_update = time.time()

        logger.info("metrics_collector_initialized")

    def record_request(
        self,
        method: str,
        endpoint: str,
        status_code: int,
        duration: float,
        user_id: str | None = None,
    ) -> None:
        """Record request metrics."""
        labels = {
            "method": method,
            "endpoint": endpoint,
            "status_code": str(status_code),
            "user_id": user_id or "anonymous",
        }

        self.request_total.labels(**labels).inc()
        self.request_duration.labels(method=method, endpoint=endpoint).observe(duration)

        # Update internal tracking
        self.request_counts[f"{method}:{endpoint}"] += 1

    def record_provider_request(
        self,
        provider: str,
        model: str,
        status: str,
        duration: float,
        input_tokens: int = 0,
        output_tokens: int = 0,
        cost: float = 0.0,
    ) -> None:
        """Record provider-specific metrics."""
        self.provider_requests.labels(provider=provider, model=model, status=status).inc()

        self.provider_duration.labels(provider=provider, model=model).observe(duration)

        if input_tokens > 0:
            self.provider_tokens.labels(provider=provider, model=model, type="input").inc(
                input_tokens
            )

        if output_tokens > 0:
            self.provider_tokens.labels(provider=provider, model=model, type="output").inc(
                output_tokens
            )

        if cost > 0:
            self.provider_cost.labels(provider=provider, model=model).inc(cost)

    def record_routing_decision(
        self, strategy: str, selected_provider: str, selected_model: str, confidence: float
    ) -> None:
        """Record routing decision metrics."""
        self.routing_decisions.labels(
            strategy=strategy, selected_provider=selected_provider, selected_model=selected_model
        ).inc()

        self.routing_confidence.labels(strategy=strategy).observe(confidence)

    def record_classification(self, category: str, method: str, confidence: float) -> None:
        """Record classification metrics."""
        self.classification_results.labels(category=category, method=method).inc()

        self.classification_confidence.labels(category=category).observe(confidence)

    def record_rate_limit_hit(self, user_id: str, limit_type: str) -> None:
        """Record rate limit violation."""
        self.rate_limit_hits.labels(user_id=user_id, limit_type=limit_type).inc()

    def record_cache_operation(self, operation: str, result: str) -> None:
        """Record cache operation metrics."""
        self.cache_operations.labels(operation=operation, result=result).inc()

    def record_error(self, error_type: str, endpoint: str, provider: str | None = None) -> None:
        """Record error metrics."""
        self.errors_total.labels(
            error_type=error_type, endpoint=endpoint, provider=provider or "unknown"
        ).inc()

        # Update internal tracking
        self.error_counts[error_type] += 1

    def update_provider_health(self, provider: str, is_healthy: bool) -> None:
        """Update provider health status."""
        self.provider_health.labels(provider=provider).set(1 if is_healthy else 0)

    def update_active_connections(self, count: int) -> None:
        """Update active connections count."""
        self.active_connections.set(count)

    def update_memory_usage(self, rss: int, vms: int, shared: int = 0) -> None:
        """Update memory usage metrics."""
        self.memory_usage.labels(type="rss").set(rss)
        self.memory_usage.labels(type="vms").set(vms)
        if shared > 0:
            self.memory_usage.labels(type="shared").set(shared)

    def set_system_info(self, info: dict[str, str]) -> None:
        """Set system information."""
        self.system_info.info(info)

    # Enhanced Production Metrics Methods (Part 3)
    # =============================================

    def record_cascade_request(
        self,
        cascade_type: str,
        final_provider: str,
        steps_count: int,
        total_cost: float,
        quality_score: float | None = None,
        confidence_score: float | None = None,
        routing_strategy: str = "cascade",
    ) -> None:
        """Record cascade routing metrics."""
        self.cascade_steps_total.labels(
            cascade_type=cascade_type, final_provider=final_provider
        ).observe(steps_count)

        self.cost_per_request.labels(
            provider=final_provider, model="cascade", routing_strategy=routing_strategy
        ).observe(total_cost)

        if quality_score is not None:
            self.quality_score_distribution.labels(
                provider=final_provider, model="cascade"
            ).observe(quality_score)

        if confidence_score is not None:
            self.confidence_score_distribution.labels(
                provider=final_provider, model="cascade"
            ).observe(confidence_score)

    def record_single_request_cost(
        self, provider: str, model: str, cost: float, routing_strategy: str = "single"
    ) -> None:
        """Record cost for single model requests."""
        self.cost_per_request.labels(
            provider=provider, model=model, routing_strategy=routing_strategy
        ).observe(cost)

    def update_budget_utilization(
        self, user_id: str, budget_type: str, provider: str, utilization_percent: float
    ) -> None:
        """Update budget utilization metrics."""
        self.budget_utilization_ratio.labels(
            user_id=user_id, budget_type=budget_type, provider=provider
        ).set(utilization_percent)

    def record_user_activity(self, user_id: str) -> None:
        """Record user activity for active users tracking."""
        current_time = time.time()
        self.active_users_set.add((user_id, current_time))

        # Clean up old entries every 5 minutes
        if current_time - self.last_active_users_update > 300:
            cutoff_time = current_time - 86400  # 24 hours ago
            self.active_users_set = {
                (uid, timestamp)
                for uid, timestamp in self.active_users_set
                if timestamp > cutoff_time
            }

            # Update active users count
            unique_users = len({uid for uid, _ in self.active_users_set})
            self.active_users.set(unique_users)
            self.last_active_users_update = current_time

    def update_cache_hit_ratio(self, cache_type: str, hit_ratio: float) -> None:
        """Update cache hit ratio metrics."""
        self.cache_hit_ratio.labels(cache_type=cache_type).set(hit_ratio)

    def record_organization_activity(self, org_id: str, plan_type: str, cost: float = 0.0) -> None:
        """Record organization-level metrics."""
        self.organization_requests.labels(org_id=org_id, plan_type=plan_type).inc()

        if cost > 0:
            self.organization_cost.labels(org_id=org_id, plan_type=plan_type).inc(cost)

    def record_auth_attempt(self, method: str, result: str, user_type: str = "user") -> None:
        """Record authentication attempts."""
        self.auth_attempts.labels(method=method, result=result, user_type=user_type).inc()

    def record_pii_detection(self, pii_type: str, action_taken: str) -> None:
        """Record PII detection events."""
        self.pii_detections.labels(pii_type=pii_type, action_taken=action_taken).inc()

    def get_summary_stats(self) -> dict[str, Any]:
        """Get summary statistics."""
        current_time = time.time()
        uptime = current_time - self.start_time

        return {
            "uptime_seconds": uptime,
            "total_requests": sum(self.request_counts.values()),
            "total_errors": sum(self.error_counts.values()),
            "requests_per_endpoint": dict(self.request_counts),
            "errors_by_type": dict(self.error_counts),
            "error_rate": sum(self.error_counts.values())
            / max(sum(self.request_counts.values()), 1),
        }

    def reset_counters(self) -> None:
        """Reset internal counters (not Prometheus metrics)."""
        self.request_counts.clear()
        self.error_counts.clear()
        logger.info("internal_counters_reset")


class HealthChecker:
    """
    Health check system for ModelMuxer components.

    Monitors the health of providers, cache, database, and other
    critical system components.
    """

    def __init__(self, metrics_collector: MetricsCollector | None = None):
        self.metrics_collector = metrics_collector
        self.health_checks: dict[str, dict[str, Any]] = {}
        self.last_check_time = 0
        self.check_interval = 30  # seconds

        logger.info("health_checker_initialized")

    async def check_provider_health(self, provider_name: str, provider: Any) -> bool:
        """Check health of a specific provider."""
        try:
            is_healthy_result = await provider.health_check()
            is_healthy = bool(is_healthy_result)

            self.health_checks[f"provider_{provider_name}"] = {
                "status": "healthy" if is_healthy else "unhealthy",
                "last_check": time.time(),
                "error": None,
            }

            if self.metrics_collector:
                self.metrics_collector.update_provider_health(provider_name, is_healthy)

            return is_healthy

        except Exception as e:
            self.health_checks[f"provider_{provider_name}"] = {
                "status": "unhealthy",
                "last_check": time.time(),
                "error": str(e),
            }

            if self.metrics_collector:
                self.metrics_collector.update_provider_health(provider_name, False)

            logger.error("provider_health_check_failed", provider=provider_name, error=str(e))
            return False

    async def check_cache_health(self, cache: Any) -> bool:
        """Check cache system health."""
        try:
            # Try a simple cache operation
            test_key = "health_check_test"
            test_value = "test_value"

            await cache.set(test_key, test_value, ttl=10)
            retrieved_value = await cache.get(test_key)
            await cache.delete(test_key)

            is_healthy = bool(retrieved_value == test_value)

            self.health_checks["cache"] = {
                "status": "healthy" if is_healthy else "unhealthy",
                "last_check": time.time(),
                "error": None,
            }

            return is_healthy

        except Exception as e:
            self.health_checks["cache"] = {
                "status": "unhealthy",
                "last_check": time.time(),
                "error": str(e),
            }

            logger.error("cache_health_check_failed", error=str(e))
            return False

    def check_system_resources(self) -> dict[str, Any]:
        """Check system resource health."""
        try:
            import psutil

            # CPU usage
            cpu_percent = psutil.cpu_percent(interval=1)

            # Memory usage
            memory = psutil.virtual_memory()

            # Disk usage
            disk = psutil.disk_usage("/")

            # System load
            load_avg = psutil.getloadavg() if hasattr(psutil, "getloadavg") else (0, 0, 0)

            resource_status = {
                "cpu_percent": cpu_percent,
                "memory_percent": memory.percent,
                "memory_available": memory.available,
                "disk_percent": disk.percent,
                "disk_free": disk.free,
                "load_avg_1m": load_avg[0],
                "load_avg_5m": load_avg[1],
                "load_avg_15m": load_avg[2],
            }

            # Determine overall health
            is_healthy = cpu_percent < 90 and memory.percent < 90 and disk.percent < 90

            self.health_checks["system_resources"] = {
                "status": "healthy" if is_healthy else "unhealthy",
                "last_check": time.time(),
                "details": resource_status,
                "error": None,
            }

            # Update metrics if available
            if self.metrics_collector:
                rss_value = getattr(memory, "rss", 0)
                vms_value = getattr(memory, "vms", 0)
                self.metrics_collector.update_memory_usage(rss_value, vms_value)

            return resource_status

        except ImportError:
            logger.warning("psutil_not_available_for_system_health_check")
            return {}
        except Exception as e:
            logger.error("system_health_check_failed", error=str(e))
            return {}

    def get_overall_health(self) -> dict[str, Any]:
        """Get overall system health status."""
        current_time = time.time()

        # Count healthy vs unhealthy components
        healthy_count = 0
        unhealthy_count = 0
        total_count = len(self.health_checks)

        for status in self.health_checks.values():
            if status["status"] == "healthy":
                healthy_count += 1
            else:
                unhealthy_count += 1

        # Determine overall status
        if unhealthy_count == 0:
            overall_status = "healthy"
        elif healthy_count > unhealthy_count:
            overall_status = "degraded"
        else:
            overall_status = "unhealthy"

        return {
            "status": overall_status,
            "timestamp": current_time,
            "components": self.health_checks.copy(),
            "summary": {
                "total_components": total_count,
                "healthy_components": healthy_count,
                "unhealthy_components": unhealthy_count,
            },
        }
