# ModelMuxer example environment configuration

# --- Provider API Keys (optional) ---
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
# MISTRAL_API_KEY=
# GROQ_API_KEY=

# --- LiteLLM proxy (optional) ---
# LITELLM_BASE_URL=
# LITELLM_API_KEY=

# --- Observability ---
# ENABLE_TRACING=true
# ENABLE_METRICS=true
# OTEL_EXPORTER_OTLP_ENDPOINT=

# --- Server ---
# SERVER_HOST=0.0.0.0
# SERVER_PORT=8000
# SERVER_DEBUG=false

# --- Router Defaults ---
# ROUTER_DEFAULT_MODEL=gpt-3.5-turbo

# --- Intent Classifier (Phase 1) ---
ROUTER_INTENT_CLASSIFIER_ENABLED=true
INTENT_LOW_CONFIDENCE=0.4
INTENT_MIN_CONF_FOR_DIRECT=0.7

# --- Test Mode ---
# TEST_MODE=false
# =============================================================================
# ModelMuxer Environment Configuration
# =============================================================================
# Copy this file to .env and update with your actual values
# Never commit .env files with real credentials to version control

# =============================================================================
# API Keys Configuration
# =============================================================================
# LLM Provider API Keys (Required - at least one provider)
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
MISTRAL_API_KEY=your-mistral-key-here
GOOGLE_API_KEY=your-google-api-key-here
GROQ_API_KEY=gsk_your-groq-key-here
TOGETHER_API_KEY=your-together-api-key-here
COHERE_API_KEY=your-cohere-api-key-here

# LiteLLM Proxy Configuration (Optional)
LITELLM_BASE_URL=http://localhost:4000
LITELLM_API_KEY=your-litellm-api-key-here

# ModelMuxer API Key for CLI
MODELMUXER_API_KEY=your-api-key-here

# =============================================================================
# Database Configuration
# =============================================================================
# SQLite (Development)
DATABASE_URL=sqlite:///./modelmuxer.db

# PostgreSQL (Production)
# DATABASE_URL=postgresql://username:SECURE_PASSWORD@localhost:5432/modelmuxer

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis URL for caching and session storage
REDIS_URL=redis://localhost:6379
REDIS_DB=0
REDIS_TLS=false

# =============================================================================
# Server Configuration
# =============================================================================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# =============================================================================
# Security Configuration
# =============================================================================
# API Key Authentication
API_KEY_HEADER=X-API-Key
ALLOWED_API_KEYS=sk-test-key-1,sk-test-key-2

# JWT Configuration
JWT_SECRET_KEY=REPLACE-WITH-SECURE-32-CHAR-SECRET-KEY-IN-PRODUCTION
JWT_ALGORITHM=HS256
JWT_EXPIRY=3600

# CLI Security
ALLOW_EXTERNAL_CLI_URLS=false

# =============================================================================
# Observability Configuration
# =============================================================================
# CORS Configuration (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080,https://modelmuxer.com

# Logging
LOG_LEVEL=info
LOG_FORMAT=json
LOG_STRUCTURED=true

# Prometheus Metrics
PROMETHEUS_ENABLED=true

# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Sentry Error Reporting
SENTRY_DSN=https://your-sentry-dsn@sentry.io/project

# =============================================================================
# Feature Flags
# =============================================================================
# ModelMuxer Mode: basic, enhanced, production
MODELMUXER_MODE=basic

# Core Features
AUTH_ENABLED=true
RATE_LIMIT_ENABLED=true
MONITORING_ENABLED=true
CACHE_ENABLED=true

# Routing Features
ENABLE_SEMANTIC_ROUTING=true
ENABLE_CASCADE_ROUTING=true
ENABLE_LITELLM=true

# =============================================================================
# Router Configuration
# =============================================================================
# Default Model and Parameters
DEFAULT_MODEL=gpt-4o-mini
MAX_TOKENS_DEFAULT=1000
TEMPERATURE_DEFAULT=0.7

# Routing Thresholds
CODE_DETECTION_THRESHOLD=0.2
COMPLEXITY_THRESHOLD=0.2
SIMPLE_QUERY_MAX_LENGTH=100

# =============================================================================
# Provider Pricing (Cost per million tokens)
# =============================================================================
# OpenAI Pricing
OPENAI_GPT4O_INPUT_PRICE=5.0
OPENAI_GPT4O_OUTPUT_PRICE=15.0
OPENAI_GPT4O_MINI_INPUT_PRICE=0.15
OPENAI_GPT4O_MINI_OUTPUT_PRICE=0.6
OPENAI_GPT35_TURBO_INPUT_PRICE=0.5
OPENAI_GPT35_TURBO_OUTPUT_PRICE=1.5
OPENAI_GPT4_INPUT_PRICE=30.0
OPENAI_GPT4_OUTPUT_PRICE=60.0
OPENAI_GPT4_TURBO_INPUT_PRICE=10.0
OPENAI_GPT4_TURBO_OUTPUT_PRICE=30.0

# Anthropic Pricing
ANTHROPIC_CLAUDE_35_SONNET_INPUT_PRICE=3.0
ANTHROPIC_CLAUDE_35_SONNET_OUTPUT_PRICE=15.0
ANTHROPIC_CLAUDE_3_HAIKU_INPUT_PRICE=0.25
ANTHROPIC_CLAUDE_3_HAIKU_OUTPUT_PRICE=1.25
ANTHROPIC_CLAUDE_3_OPUS_INPUT_PRICE=15.0
ANTHROPIC_CLAUDE_3_OPUS_OUTPUT_PRICE=75.0

# Mistral Pricing
MISTRAL_SMALL_INPUT_PRICE=0.2
MISTRAL_SMALL_OUTPUT_PRICE=0.6
MISTRAL_MEDIUM_INPUT_PRICE=2.7
MISTRAL_MEDIUM_OUTPUT_PRICE=8.1
MISTRAL_LARGE_INPUT_PRICE=8.0
MISTRAL_LARGE_OUTPUT_PRICE=24.0

# Google Pricing
GOOGLE_GEMINI_PRO_INPUT_PRICE=0.5
GOOGLE_GEMINI_PRO_OUTPUT_PRICE=1.5
GOOGLE_GEMINI_PRO_VISION_INPUT_PRICE=0.5
GOOGLE_GEMINI_PRO_VISION_OUTPUT_PRICE=1.5

# Groq Pricing
GROQ_LLAMA2_70B_INPUT_PRICE=0.7
GROQ_LLAMA2_70B_OUTPUT_PRICE=0.8
GROQ_MIXTRAL_8X7B_INPUT_PRICE=0.2
GROQ_MIXTRAL_8X7B_OUTPUT_PRICE=0.2

# Cohere Pricing
COHERE_COMMAND_INPUT_PRICE=1.0
COHERE_COMMAND_OUTPUT_PRICE=2.0
COHERE_COMMAND_LIGHT_INPUT_PRICE=0.3
COHERE_COMMAND_LIGHT_OUTPUT_PRICE=0.6

# Together AI Pricing
TOGETHER_LLAMA2_70B_INPUT_PRICE=0.7
TOGETHER_LLAMA2_70B_OUTPUT_PRICE=0.8
TOGETHER_MIXTRAL_8X7B_INPUT_PRICE=0.2
TOGETHER_MIXTRAL_8X7B_OUTPUT_PRICE=0.2

# =============================================================================
# Legacy Configuration (for backward compatibility)
# =============================================================================
# These settings are maintained for compatibility with existing deployments
# but are now managed through the centralized settings system

# Rate Limiting (Legacy)
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
RATE_LIMIT_BURST=10

# Monitoring (Legacy)
HEALTH_CHECK_ENABLED=true
METRICS_INTERVAL=60

# Enhanced Features (Legacy)
ENHANCED_FEATURES_AVAILABLE=true

# =============================================================================
# Policy Configuration
# =============================================================================
FEATURES_REDACT_PII=true
POLICY_ENABLE_JAILBREAK_DETECTION=true
POLICY_JAILBREAK_PATTERNS_PATH=app/policy/patterns/jailbreak.txt
# Example JSON maps for allow/deny (quoted strings):
POLICY_MODEL_ALLOW='{"tenant_a":["gpt-4o","claude-3-opus"]}'
POLICY_MODEL_DENY='{"tenant_a":["gpt-4o-mini"]}'
POLICY_REGION_ALLOW='{"tenant_a":["eu","us"]}'
POLICY_REGION_DENY='{"tenant_a":["cn","ru"]}'
